{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins>Training of Object detection models</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using the pre-processed data the one we did in <mark>DL_Coursework_Pre_Processing.ipynb</mark> file we will train two different object detection models which are pre-trained on <mark>COCO 2017 dataset</mark>. The purpose of choosing two models is to check which yields the best results. Following are the two object detection models which has been used.\n",
    "\n",
    "| Model Name | Speed (ms) | COCO mAP | Output |\n",
    "| --- | --- | --- | --- |\n",
    "| Faster R-CNN ResNet101 V1 1024x1024 | 72 | 37.1 | Boxes |\n",
    "| Faster R-CNN Inception ResNet V2 1024x1024 | 236 | 38.7 | Boxes |\n",
    "\n",
    "### Note: ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8 has been tried for the object detection but it was giving too much bad results. Furthermore we SSD is not good at detecting small objects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>Faster R-CNN Resnet101 with 1024x1024 image size</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  This object detection model is from [TensorFlow Hub](https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_1024x1024/1 ). This pre-build object detection model has <mark>101</mark> deep layers. It accepts an image as input and outputs bounding boxes for the image's objects. The aim of the model is to identify the objects and their locations in the photos of COCO 2017, which contains images with multiple objects. \n",
    "\n",
    "### The pre-build model from tensorflow has been download to train the model for the bird's dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MODEL = \"faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8\" # assign folder name to variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins>Configure the config file</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After downloading the pre-build model from the TensorFlow, model has been pasted in our directory so we can train the model on our dataset. To use the pre-build model we have to make the configuration settings according to our dataset. Following are the settings we made to use it.\n",
    "\n",
    "<ol>\n",
    "    <li>\n",
    "        Number of classes changed to <mark>3</mark> because we are doing detection of 3 classes.\n",
    "    </li>\n",
    "    <li>\n",
    "        Batch size changed to <mark>1</mark> because we are using single GPU. \n",
    "    </li>\n",
    "    <li>\n",
    "        Path has been given for fine tune checkpoint of faster-rcnn resnet101\n",
    "    </li>\n",
    "    <li>\n",
    "        Fine tune checkpoint type has been set to <mark>detection</mark>\n",
    "    </li>\n",
    "    <li>\n",
    "        TF records path has been provided\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "#### By using the below command, pipline config has been accessed and we made above listed changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!code './training/TF2/training/'{PATH_TO_MODEL}'/pipeline.config' # This will open the configuration file of faster-rcnn resent101 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yhzxsJb3dpWq"
   },
   "source": [
    "### <ins>Setting model hyperparameters and training</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once the configuration in <mark>pipiline.config</mark> has been set we can set the hyperparameters and pass it to <mark>model_main_tf2.py</mark> file. In this file, object detection packages has been used from tensorflow to train the model. \n",
    "\n",
    "#### For this model we set the <mark>num_train_steps = 17000</mark>, on this training steps, getting the best results of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-09 09:07:06.701482: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-09 09:07:07.934173: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-01-09 09:07:07.960527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 09:07:07.961242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-01-09 09:07:07.961265: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-09 09:07:07.963652: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-01-09 09:07:07.963700: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-01-09 09:07:07.964485: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-09 09:07:07.964689: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-09 09:07:07.965458: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-01-09 09:07:07.965857: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-01-09 09:07:07.965929: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-01-09 09:07:07.965982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 09:07:07.966447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 09:07:07.966875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-01-09 09:07:07.967053: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-09 09:07:07.967560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 09:07:07.967994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-01-09 09:07:07.968034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 09:07:07.968484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 09:07:07.968905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-01-09 09:07:07.968924: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-09 09:07:08.274724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-01-09 09:07:08.274746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2023-01-09 09:07:08.274753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2023-01-09 09:07:08.274889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 09:07:08.275409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 09:07:08.275880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 09:07:08.276327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22289 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "W0109 09:07:08.277917 140188289831744 mirrored_strategy.py:379] Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I0109 09:07:08.435899 140188289831744 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 17050\n",
      "I0109 09:07:08.437816 140188289831744 config_util.py:552] Maybe overwriting train_steps: 17050\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0109 09:07:08.437883 140188289831744 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/object_detection/model_lib_v2.py:557: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0109 09:07:08.453148 140188289831744 deprecation.py:330] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/object_detection/model_lib_v2.py:557: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['data/train.record']\n",
      "I0109 09:07:08.455014 140188289831744 dataset_builder.py:163] Reading unweighted datasets: ['data/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['data/train.record']\n",
      "I0109 09:07:08.455113 140188289831744 dataset_builder.py:80] Reading record datasets for input file: ['data/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0109 09:07:08.455157 140188289831744 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0109 09:07:08.455205 140188289831744 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W0109 09:07:08.456836 140188289831744 deprecation.py:330] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0109 09:07:08.468107 140188289831744 deprecation.py:330] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0109 09:07:11.925673 140188289831744 deprecation.py:330] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0109 09:07:14.264301 140188289831744 deprecation.py:330] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2023-01-09 09:07:15.417586: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-01-09 09:07:15.437345: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3699850000 Hz\n",
      "/home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:435: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0109 09:07:19.642215 140152567494400 convolutional_keras_box_predictor.py:153] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "W0109 09:07:23.105990 140152567494400 deprecation.py:330] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W0109 09:07:25.414034 140152567494400 deprecation.py:330] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "2023-01-09 09:07:31.301140: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-01-09 09:07:31.668615: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8100\n",
      "2023-01-09 09:07:32.166941: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-01-09 09:07:32.520208: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-01-09 09:07:32.626653: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0109 09:07:35.733040 140153054009088 deprecation.py:528] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "INFO:tensorflow:Step 17100 per-step time 0.362s\n",
      "I0109 09:08:11.661261 140188289831744 model_lib_v2.py:698] Step 17100 per-step time 0.362s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.028884985,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.15400343,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.002207201,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.18509562,\n",
      " 'learning_rate': 0.0003770224}\n",
      "I0109 09:08:11.661432 140188289831744 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.028884985,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.15400343,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.002207201,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.18509562,\n",
      " 'learning_rate': 0.0003770224}\n"
     ]
    }
   ],
   "source": [
    "!python model_main_tf2.py --model_dir=training/TF2/training/{PATH_TO_MODEL} --pipeline_config_path=training/TF2/training/{PATH_TO_MODEL}/pipeline.config --num_train_steps=17000 --alsologtostderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins>Exporting a Trained Inference Graph</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OmSESMetj1sa"
   },
   "source": [
    "#### Once our training of the model is complete, we are extracting the newly inferenced graph, which will be later use to perform the object detection. \n",
    "\n",
    "#### The following file <mark>exporter_main_v2.py</mark> uses model configuration and a trained checkpoint to get ready an object detection tensorflow graph for inference. In the output of this file, we are getting checkpoint files, a SavedModel, and a copy of the model config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GStNeHWPkTcN",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-09 09:08:13.225652: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-09 09:08:14.315942: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-01-09 09:08:14.336195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 09:08:14.336630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-01-09 09:08:14.336644: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-09 09:08:14.338209: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-01-09 09:08:14.338237: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-01-09 09:08:14.338744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-09 09:08:14.338870: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-09 09:08:14.339349: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-01-09 09:08:14.339753: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-01-09 09:08:14.339822: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-01-09 09:08:14.339870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 09:08:14.340317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 09:08:14.340733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-01-09 09:08:14.340876: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-09 09:08:14.341419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 09:08:14.341839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-01-09 09:08:14.341880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 09:08:14.342317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 09:08:14.342724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-01-09 09:08:14.342742: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-09 09:08:14.630133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-01-09 09:08:14.630154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2023-01-09 09:08:14.630159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2023-01-09 09:08:14.630274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 09:08:14.630742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 09:08:14.631181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 09:08:14.631603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22289 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W0109 09:08:14.898935 139795177337664 deprecation.py:596] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0109 09:08:18.321419 139795177337664 convolutional_keras_box_predictor.py:153] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "W0109 09:08:22.091755 139795177337664 deprecation.py:330] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "2023-01-09 09:08:23.677095: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-01-09 09:08:23.697514: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3699850000 Hz\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.faster_rcnn_meta_arch.FasterRCNNMetaArch object at 0x7f237d399190>, because it is not built.\n",
      "W0109 09:08:26.148656 139795177337664 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.meta_architectures.faster_rcnn_meta_arch.FasterRCNNMetaArch object at 0x7f237d399190>, because it is not built.\n",
      "2023-01-09 09:08:32.673261: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "W0109 09:08:43.988479 139795177337664 save.py:238] Found untraced functions such as FirstStageBoxPredictor_layer_call_and_return_conditional_losses, FirstStageBoxPredictor_layer_call_fn, mask_rcnn_keras_box_predictor_layer_call_and_return_conditional_losses, mask_rcnn_keras_box_predictor_layer_call_fn, FirstStageBoxPredictor_layer_call_fn while saving (showing 5 of 70). These functions will not be directly callable after loading.\n",
      "/home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n",
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "W0109 09:08:47.113591 139795177337664 save.py:1239] FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "INFO:tensorflow:Assets written to: ./training/TF2/training/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8/saved_model/saved_model/assets\n",
      "I0109 09:08:47.668667 139795177337664 builder_impl.py:774] Assets written to: ./training/TF2/training/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8/saved_model/saved_model/assets\n",
      "INFO:tensorflow:Writing pipeline config file to ./training/TF2/training/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8/saved_model/pipeline.config\n",
      "I0109 09:08:48.196971 139795177337664 config_util.py:253] Writing pipeline config file to ./training/TF2/training/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8/saved_model/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path ./training/TF2/training/{PATH_TO_MODEL}/pipeline.config --trained_checkpoint_dir ./training/TF2/training/{PATH_TO_MODEL}/ --output_directory ./training/TF2/training/{PATH_TO_MODEL}/saved_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>Faster R-CNN Inception ResNet V2 1024x1024</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  This object detection model is from [TensorFlow Hub](https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_1024x1024/1 ). It accepts an image as input and outputs bounding boxes for the image's objects. The aim of the model is to identify the objects and their locations in the photos of COCO 2017, which contains images with multiple objects. \n",
    "\n",
    "### The pre-build model from tensorflow has been download to train the model for the bird's dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MODEL = \"faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins>Configure the config file</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After downloading the pre-build model from the TensorFlow, model has been pasted in our directory so we can train the model on our dataset. To use the pre-build model we have to make the configuration settings according to our dataset. Following are the settings we made to use it.\n",
    "\n",
    "<ol>\n",
    "    <li>\n",
    "        Number of classes changed to <mark>3</mark> because we are doing detection of 3 classes.\n",
    "    </li>\n",
    "    <li>\n",
    "        Batch size changed to <mark>1</mark> because we are using single GPU. \n",
    "    </li>\n",
    "    <li>\n",
    "        Path has been given for fine tune checkpoint of faster-rcnn resnet101\n",
    "    </li>\n",
    "    <li>\n",
    "        Fine tune checkpoint type has been set to <mark>detection</mark>\n",
    "    </li>\n",
    "    <li>\n",
    "        TF records path has been provided\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "#### By using the below command, pipline config has been accessed and we made above listed changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!code './training/TF2/training/'{PATH_TO_MODEL}'/pipeline.config' # This will open the configuration file of faster-rcnn resent101 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins>Setting model hyperparameters and training</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once the configuration in <mark>pipiline.config</mark> has been set we can set the hyperparameters and pass it to <mark>model_main_tf2.py</mark> file. In this file, object detection packages has been used from tensorflow to train the model. \n",
    "\n",
    "#### For this model we set the <mark>num_train_steps = 21000</mark>, on this training steps, getting the best results of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-09 11:05:25.509854: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-09 11:05:26.757061: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-01-09 11:05:26.783726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 11:05:26.784284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-01-09 11:05:26.784301: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-09 11:05:26.786210: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-01-09 11:05:26.786247: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-01-09 11:05:26.786876: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-09 11:05:26.787033: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-09 11:05:26.787646: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-01-09 11:05:26.788140: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-01-09 11:05:26.788232: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-01-09 11:05:26.788293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 11:05:26.788872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 11:05:26.789427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-01-09 11:05:26.789607: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-09 11:05:26.790099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 11:05:26.790526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-01-09 11:05:26.790568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 11:05:26.791016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 11:05:26.791434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-01-09 11:05:26.791452: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-09 11:05:27.085860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-01-09 11:05:27.085879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2023-01-09 11:05:27.085885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2023-01-09 11:05:27.086012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 11:05:27.086483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 11:05:27.086918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 11:05:27.087337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21674 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "W0109 11:05:27.088943 139661106783040 mirrored_strategy.py:379] Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I0109 11:05:27.242365 139661106783040 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 21000\n",
      "I0109 11:05:27.244137 139661106783040 config_util.py:552] Maybe overwriting train_steps: 21000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0109 11:05:27.244195 139661106783040 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/object_detection/model_lib_v2.py:557: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0109 11:05:27.259368 139661106783040 deprecation.py:330] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/object_detection/model_lib_v2.py:557: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['data/train.record']\n",
      "I0109 11:05:27.261310 139661106783040 dataset_builder.py:163] Reading unweighted datasets: ['data/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['data/train.record']\n",
      "I0109 11:05:27.261403 139661106783040 dataset_builder.py:80] Reading record datasets for input file: ['data/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0109 11:05:27.261445 139661106783040 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0109 11:05:27.261481 139661106783040 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W0109 11:05:27.263000 139661106783040 deprecation.py:330] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0109 11:05:27.274466 139661106783040 deprecation.py:330] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0109 11:05:30.761881 139661106783040 deprecation.py:330] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0109 11:05:33.281612 139661106783040 deprecation.py:330] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2023-01-09 11:05:34.435375: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-01-09 11:05:34.457345: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3699850000 Hz\n",
      "/home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:435: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0109 11:05:40.515532 139626333320960 convolutional_keras_box_predictor.py:153] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "W0109 11:05:43.219183 139626333320960 deprecation.py:528] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "W0109 11:05:43.562378 139626333320960 deprecation.py:330] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W0109 11:05:46.219304 139626333320960 deprecation.py:330] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "2023-01-09 11:05:54.575454: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-01-09 11:05:54.948692: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8100\n",
      "2023-01-09 11:05:55.440062: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-01-09 11:05:55.790731: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-01-09 11:05:57.167249: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0109 11:06:03.868680 139626341713664 deprecation.py:528] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "INFO:tensorflow:Step 17100 per-step time 0.636s\n",
      "I0109 11:07:07.152664 139661106783040 model_lib_v2.py:698] Step 17100 per-step time 0.636s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.19168846,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.8195548,\n",
      " 'Loss/RPNLoss/localization_loss': 0.031522095,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.004775686,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 1.0475409,\n",
      " 'learning_rate': 0.007924237}\n",
      "I0109 11:07:07.152837 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.19168846,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.8195548,\n",
      " 'Loss/RPNLoss/localization_loss': 0.031522095,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.004775686,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 1.0475409,\n",
      " 'learning_rate': 0.007924237}\n",
      "INFO:tensorflow:Step 17200 per-step time 0.207s\n",
      "I0109 11:07:27.812910 139661106783040 model_lib_v2.py:698] Step 17200 per-step time 0.207s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.10400965,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.14921452,\n",
      " 'Loss/RPNLoss/localization_loss': 0.018136714,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0019561667,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.27331704,\n",
      " 'learning_rate': 0.007922985}\n",
      "I0109 11:07:27.813059 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.10400965,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.14921452,\n",
      " 'Loss/RPNLoss/localization_loss': 0.018136714,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0019561667,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.27331704,\n",
      " 'learning_rate': 0.007922985}\n",
      "INFO:tensorflow:Step 17300 per-step time 0.208s\n",
      "I0109 11:07:48.578773 139661106783040 model_lib_v2.py:698] Step 17300 per-step time 0.208s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.07904344,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.15547076,\n",
      " 'Loss/RPNLoss/localization_loss': 0.010426097,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0030355796,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.24797589,\n",
      " 'learning_rate': 0.007921721}\n",
      "I0109 11:07:48.578922 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.07904344,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.15547076,\n",
      " 'Loss/RPNLoss/localization_loss': 0.010426097,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0030355796,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.24797589,\n",
      " 'learning_rate': 0.007921721}\n",
      "INFO:tensorflow:Step 17400 per-step time 0.207s\n",
      "I0109 11:08:09.325496 139661106783040 model_lib_v2.py:698] Step 17400 per-step time 0.207s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.099447295,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.21712051,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0155381495,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.010148952,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.3422549,\n",
      " 'learning_rate': 0.007920447}\n",
      "I0109 11:08:09.325644 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.099447295,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.21712051,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0155381495,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.010148952,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.3422549,\n",
      " 'learning_rate': 0.007920447}\n",
      "INFO:tensorflow:Step 17500 per-step time 0.209s\n",
      "I0109 11:08:30.222351 139661106783040 model_lib_v2.py:698] Step 17500 per-step time 0.209s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.07465403,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.07318231,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0041945875,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0018368864,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.1538678,\n",
      " 'learning_rate': 0.007919163}\n",
      "I0109 11:08:30.222531 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.07465403,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.07318231,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0041945875,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0018368864,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.1538678,\n",
      " 'learning_rate': 0.007919163}\n",
      "INFO:tensorflow:Step 17600 per-step time 0.209s\n",
      "I0109 11:08:51.118902 139661106783040 model_lib_v2.py:698] Step 17600 per-step time 0.209s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.010482942,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.0,\n",
      " 'Loss/RPNLoss/localization_loss': 0.10874614,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.031001594,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.15023068,\n",
      " 'learning_rate': 0.007917869}\n",
      "I0109 11:08:51.119054 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.010482942,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.0,\n",
      " 'Loss/RPNLoss/localization_loss': 0.10874614,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.031001594,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.15023068,\n",
      " 'learning_rate': 0.007917869}\n",
      "INFO:tensorflow:Step 17700 per-step time 0.209s\n",
      "I0109 11:09:11.997767 139661106783040 model_lib_v2.py:698] Step 17700 per-step time 0.209s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.2232418,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.7636561,\n",
      " 'Loss/RPNLoss/localization_loss': 0.01753465,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.004514273,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 1.0089468,\n",
      " 'learning_rate': 0.007916564}\n",
      "I0109 11:09:11.997911 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.2232418,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.7636561,\n",
      " 'Loss/RPNLoss/localization_loss': 0.01753465,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.004514273,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 1.0089468,\n",
      " 'learning_rate': 0.007916564}\n",
      "INFO:tensorflow:Step 17800 per-step time 0.209s\n",
      "I0109 11:09:32.895312 139661106783040 model_lib_v2.py:698] Step 17800 per-step time 0.209s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.94033384,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.78277457,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0153774265,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.012302744,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 1.7507886,\n",
      " 'learning_rate': 0.00791525}\n",
      "I0109 11:09:32.895457 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.94033384,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.78277457,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0153774265,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.012302744,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 1.7507886,\n",
      " 'learning_rate': 0.00791525}\n",
      "INFO:tensorflow:Step 17900 per-step time 0.209s\n",
      "I0109 11:09:53.790402 139661106783040 model_lib_v2.py:698] Step 17900 per-step time 0.209s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.30445856,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.25013462,\n",
      " 'Loss/RPNLoss/localization_loss': 0.011737762,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0031297547,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.56946075,\n",
      " 'learning_rate': 0.007913926}\n",
      "I0109 11:09:53.790550 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.30445856,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.25013462,\n",
      " 'Loss/RPNLoss/localization_loss': 0.011737762,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0031297547,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.56946075,\n",
      " 'learning_rate': 0.007913926}\n",
      "INFO:tensorflow:Step 18000 per-step time 0.209s\n",
      "I0109 11:10:14.715150 139661106783040 model_lib_v2.py:698] Step 18000 per-step time 0.209s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.18515158,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.05856763,\n",
      " 'Loss/RPNLoss/localization_loss': 0.08250018,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.025619011,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.3518384,\n",
      " 'learning_rate': 0.007912591}\n",
      "I0109 11:10:14.715294 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.18515158,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.05856763,\n",
      " 'Loss/RPNLoss/localization_loss': 0.08250018,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.025619011,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.3518384,\n",
      " 'learning_rate': 0.007912591}\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0109 11:10:15.089042 139661106783040 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0109 11:10:15.089570 139661106783040 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0109 11:10:15.090360 139661106783040 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0109 11:10:15.090781 139661106783040 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0109 11:10:15.091568 139661106783040 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0109 11:10:15.091986 139661106783040 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0109 11:10:15.092764 139661106783040 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0109 11:10:15.093179 139661106783040 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0109 11:10:15.094055 139661106783040 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0109 11:10:15.094488 139661106783040 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Step 18100 per-step time 0.220s\n",
      "I0109 11:10:36.702684 139661106783040 model_lib_v2.py:698] Step 18100 per-step time 0.220s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.063087255,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.3018008,\n",
      " 'Loss/RPNLoss/localization_loss': 0.052049264,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.014516878,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.43145418,\n",
      " 'learning_rate': 0.007911245}\n",
      "I0109 11:10:36.702836 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.063087255,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.3018008,\n",
      " 'Loss/RPNLoss/localization_loss': 0.052049264,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.014516878,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.43145418,\n",
      " 'learning_rate': 0.007911245}\n",
      "INFO:tensorflow:Step 18200 per-step time 0.209s\n",
      "I0109 11:10:57.644286 139661106783040 model_lib_v2.py:698] Step 18200 per-step time 0.209s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.15388872,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.16377291,\n",
      " 'Loss/RPNLoss/localization_loss': 0.010620248,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.003878876,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.33216074,\n",
      " 'learning_rate': 0.00790989}\n",
      "I0109 11:10:57.644434 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.15388872,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.16377291,\n",
      " 'Loss/RPNLoss/localization_loss': 0.010620248,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.003878876,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.33216074,\n",
      " 'learning_rate': 0.00790989}\n",
      "INFO:tensorflow:Step 18300 per-step time 0.209s\n",
      "I0109 11:11:18.578954 139661106783040 model_lib_v2.py:698] Step 18300 per-step time 0.209s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.050926227,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.1450308,\n",
      " 'Loss/RPNLoss/localization_loss': 0.019379875,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0027887262,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.21812561,\n",
      " 'learning_rate': 0.007908526}\n",
      "I0109 11:11:18.579109 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.050926227,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.1450308,\n",
      " 'Loss/RPNLoss/localization_loss': 0.019379875,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0027887262,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.21812561,\n",
      " 'learning_rate': 0.007908526}\n",
      "INFO:tensorflow:Step 18400 per-step time 0.209s\n",
      "I0109 11:11:39.483865 139661106783040 model_lib_v2.py:698] Step 18400 per-step time 0.209s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.5759504,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.06268718,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0066588456,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0016973444,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.64699376,\n",
      " 'learning_rate': 0.00790715}\n",
      "I0109 11:11:39.484016 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.5759504,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.06268718,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0066588456,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0016973444,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.64699376,\n",
      " 'learning_rate': 0.00790715}\n",
      "INFO:tensorflow:Step 18500 per-step time 0.209s\n",
      "I0109 11:12:00.427872 139661106783040 model_lib_v2.py:698] Step 18500 per-step time 0.209s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.1671769,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.38929614,\n",
      " 'Loss/RPNLoss/localization_loss': 0.01305234,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0015170028,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.57104236,\n",
      " 'learning_rate': 0.0079057645}\n",
      "I0109 11:12:00.428049 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.1671769,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.38929614,\n",
      " 'Loss/RPNLoss/localization_loss': 0.01305234,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0015170028,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.57104236,\n",
      " 'learning_rate': 0.0079057645}\n",
      "INFO:tensorflow:Step 18600 per-step time 0.210s\n",
      "I0109 11:12:21.413068 139661106783040 model_lib_v2.py:698] Step 18600 per-step time 0.210s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.14331694,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.36828244,\n",
      " 'Loss/RPNLoss/localization_loss': 0.023210283,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.010593338,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.545403,\n",
      " 'learning_rate': 0.007904368}\n",
      "I0109 11:12:21.413216 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.14331694,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.36828244,\n",
      " 'Loss/RPNLoss/localization_loss': 0.023210283,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.010593338,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.545403,\n",
      " 'learning_rate': 0.007904368}\n",
      "INFO:tensorflow:Step 18700 per-step time 0.210s\n",
      "I0109 11:12:42.438827 139661106783040 model_lib_v2.py:698] Step 18700 per-step time 0.210s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.09036749,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.16592526,\n",
      " 'Loss/RPNLoss/localization_loss': 0.00299391,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0030237301,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.26231042,\n",
      " 'learning_rate': 0.007902963}\n",
      "I0109 11:12:42.438983 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.09036749,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.16592526,\n",
      " 'Loss/RPNLoss/localization_loss': 0.00299391,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0030237301,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.26231042,\n",
      " 'learning_rate': 0.007902963}\n",
      "INFO:tensorflow:Step 18800 per-step time 0.210s\n",
      "I0109 11:13:03.466773 139661106783040 model_lib_v2.py:698] Step 18800 per-step time 0.210s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.10506544,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.14170969,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0033871469,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0021414086,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.2523037,\n",
      " 'learning_rate': 0.0079015475}\n",
      "I0109 11:13:03.466922 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.10506544,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.14170969,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0033871469,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0021414086,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.2523037,\n",
      " 'learning_rate': 0.0079015475}\n",
      "INFO:tensorflow:Step 18900 per-step time 0.210s\n",
      "I0109 11:13:24.492148 139661106783040 model_lib_v2.py:698] Step 18900 per-step time 0.210s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.67234546,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.5721935,\n",
      " 'Loss/RPNLoss/localization_loss': 0.022553546,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.028888753,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 1.2959813,\n",
      " 'learning_rate': 0.007900121}\n",
      "I0109 11:13:24.492327 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.67234546,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.5721935,\n",
      " 'Loss/RPNLoss/localization_loss': 0.022553546,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.028888753,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 1.2959813,\n",
      " 'learning_rate': 0.007900121}\n",
      "INFO:tensorflow:Step 19000 per-step time 0.210s\n",
      "I0109 11:13:45.496340 139661106783040 model_lib_v2.py:698] Step 19000 per-step time 0.210s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.038731553,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.24016806,\n",
      " 'Loss/RPNLoss/localization_loss': 0.017820407,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0067743664,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.3034944,\n",
      " 'learning_rate': 0.007898685}\n",
      "I0109 11:13:45.496544 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.038731553,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.24016806,\n",
      " 'Loss/RPNLoss/localization_loss': 0.017820407,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0067743664,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.3034944,\n",
      " 'learning_rate': 0.007898685}\n",
      "INFO:tensorflow:Step 19100 per-step time 0.220s\n",
      "I0109 11:14:07.447914 139661106783040 model_lib_v2.py:698] Step 19100 per-step time 0.220s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.14833358,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.22461611,\n",
      " 'Loss/RPNLoss/localization_loss': 0.049259603,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.007839828,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.43004912,\n",
      " 'learning_rate': 0.007897239}\n",
      "I0109 11:14:07.448065 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.14833358,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.22461611,\n",
      " 'Loss/RPNLoss/localization_loss': 0.049259603,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.007839828,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.43004912,\n",
      " 'learning_rate': 0.007897239}\n",
      "INFO:tensorflow:Step 19200 per-step time 0.210s\n",
      "I0109 11:14:28.456321 139661106783040 model_lib_v2.py:698] Step 19200 per-step time 0.210s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.09836575,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.24934469,\n",
      " 'Loss/RPNLoss/localization_loss': 0.002290315,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.001142991,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.35114372,\n",
      " 'learning_rate': 0.007895783}\n",
      "I0109 11:14:28.456498 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.09836575,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.24934469,\n",
      " 'Loss/RPNLoss/localization_loss': 0.002290315,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.001142991,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.35114372,\n",
      " 'learning_rate': 0.007895783}\n",
      "INFO:tensorflow:Step 19300 per-step time 0.211s\n",
      "I0109 11:14:49.515053 139661106783040 model_lib_v2.py:698] Step 19300 per-step time 0.211s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.088952,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.08044753,\n",
      " 'Loss/RPNLoss/localization_loss': 0.03991004,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0056628394,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.2149724,\n",
      " 'learning_rate': 0.007894316}\n",
      "I0109 11:14:49.515235 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.088952,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.08044753,\n",
      " 'Loss/RPNLoss/localization_loss': 0.03991004,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0056628394,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.2149724,\n",
      " 'learning_rate': 0.007894316}\n",
      "INFO:tensorflow:Step 19400 per-step time 0.210s\n",
      "I0109 11:15:10.558010 139661106783040 model_lib_v2.py:698] Step 19400 per-step time 0.210s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.18677223,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.17578642,\n",
      " 'Loss/RPNLoss/localization_loss': 0.03901397,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.01536618,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.4169388,\n",
      " 'learning_rate': 0.00789284}\n",
      "I0109 11:15:10.558155 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.18677223,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.17578642,\n",
      " 'Loss/RPNLoss/localization_loss': 0.03901397,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.01536618,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.4169388,\n",
      " 'learning_rate': 0.00789284}\n",
      "INFO:tensorflow:Step 19500 per-step time 0.210s\n",
      "I0109 11:15:31.568180 139661106783040 model_lib_v2.py:698] Step 19500 per-step time 0.210s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.18639164,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.21115255,\n",
      " 'Loss/RPNLoss/localization_loss': 0.007742092,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.00045827223,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.40574455,\n",
      " 'learning_rate': 0.007891352}\n",
      "I0109 11:15:31.568330 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.18639164,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.21115255,\n",
      " 'Loss/RPNLoss/localization_loss': 0.007742092,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.00045827223,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.40574455,\n",
      " 'learning_rate': 0.007891352}\n",
      "INFO:tensorflow:Step 19600 per-step time 0.210s\n",
      "I0109 11:15:52.603031 139661106783040 model_lib_v2.py:698] Step 19600 per-step time 0.210s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.18512028,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.16474403,\n",
      " 'Loss/RPNLoss/localization_loss': 0.10104173,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.029211685,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.48011774,\n",
      " 'learning_rate': 0.007889856}\n",
      "I0109 11:15:52.603176 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.18512028,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.16474403,\n",
      " 'Loss/RPNLoss/localization_loss': 0.10104173,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.029211685,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.48011774,\n",
      " 'learning_rate': 0.007889856}\n",
      "INFO:tensorflow:Step 19700 per-step time 0.210s\n",
      "I0109 11:16:13.653568 139661106783040 model_lib_v2.py:698] Step 19700 per-step time 0.210s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.04472768,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.15640567,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0017299986,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0010091122,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.20387246,\n",
      " 'learning_rate': 0.007888349}\n",
      "I0109 11:16:13.653720 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.04472768,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.15640567,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0017299986,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0010091122,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.20387246,\n",
      " 'learning_rate': 0.007888349}\n",
      "INFO:tensorflow:Step 19800 per-step time 0.210s\n",
      "I0109 11:16:34.655977 139661106783040 model_lib_v2.py:698] Step 19800 per-step time 0.210s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.029538924,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.15812844,\n",
      " 'Loss/RPNLoss/localization_loss': 0.010569584,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0025943299,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.2008313,\n",
      " 'learning_rate': 0.007886832}\n",
      "I0109 11:16:34.656157 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.029538924,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.15812844,\n",
      " 'Loss/RPNLoss/localization_loss': 0.010569584,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0025943299,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.2008313,\n",
      " 'learning_rate': 0.007886832}\n",
      "INFO:tensorflow:Step 19900 per-step time 0.210s\n",
      "I0109 11:16:55.663327 139661106783040 model_lib_v2.py:698] Step 19900 per-step time 0.210s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.31449404,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.59948885,\n",
      " 'Loss/RPNLoss/localization_loss': 0.16495498,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.01432774,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 1.0932657,\n",
      " 'learning_rate': 0.007885305}\n",
      "I0109 11:16:55.663506 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.31449404,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.59948885,\n",
      " 'Loss/RPNLoss/localization_loss': 0.16495498,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.01432774,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 1.0932657,\n",
      " 'learning_rate': 0.007885305}\n",
      "INFO:tensorflow:Step 20000 per-step time 0.210s\n",
      "I0109 11:17:16.671021 139661106783040 model_lib_v2.py:698] Step 20000 per-step time 0.210s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.09212925,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.27933383,\n",
      " 'Loss/RPNLoss/localization_loss': 0.026470382,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0028446012,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.40077808,\n",
      " 'learning_rate': 0.007883768}\n",
      "I0109 11:17:16.671179 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.09212925,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.27933383,\n",
      " 'Loss/RPNLoss/localization_loss': 0.026470382,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0028446012,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.40077808,\n",
      " 'learning_rate': 0.007883768}\n",
      "INFO:tensorflow:Step 20100 per-step time 0.218s\n",
      "I0109 11:17:38.510194 139661106783040 model_lib_v2.py:698] Step 20100 per-step time 0.218s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.10238002,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.13336764,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0036006477,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.00057823845,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.23992655,\n",
      " 'learning_rate': 0.007882221}\n",
      "I0109 11:17:38.510346 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.10238002,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.13336764,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0036006477,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.00057823845,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.23992655,\n",
      " 'learning_rate': 0.007882221}\n",
      "INFO:tensorflow:Step 20200 per-step time 0.211s\n",
      "I0109 11:17:59.562720 139661106783040 model_lib_v2.py:698] Step 20200 per-step time 0.211s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.11994089,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.19793947,\n",
      " 'Loss/RPNLoss/localization_loss': 0.070446156,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0049146786,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.3932412,\n",
      " 'learning_rate': 0.0078806635}\n",
      "I0109 11:17:59.562866 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.11994089,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.19793947,\n",
      " 'Loss/RPNLoss/localization_loss': 0.070446156,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0049146786,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.3932412,\n",
      " 'learning_rate': 0.0078806635}\n",
      "INFO:tensorflow:Step 20300 per-step time 0.211s\n",
      "I0109 11:18:20.616562 139661106783040 model_lib_v2.py:698] Step 20300 per-step time 0.211s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.47985774,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.8040502,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0076767,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0050352933,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 1.2966199,\n",
      " 'learning_rate': 0.007879095}\n",
      "I0109 11:18:20.616757 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.47985774,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.8040502,\n",
      " 'Loss/RPNLoss/localization_loss': 0.0076767,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0050352933,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 1.2966199,\n",
      " 'learning_rate': 0.007879095}\n",
      "INFO:tensorflow:Step 20400 per-step time 0.211s\n",
      "I0109 11:18:41.669683 139661106783040 model_lib_v2.py:698] Step 20400 per-step time 0.211s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.13577577,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.10668559,\n",
      " 'Loss/RPNLoss/localization_loss': 0.002607608,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0008673378,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.24593632,\n",
      " 'learning_rate': 0.007877518}\n",
      "I0109 11:18:41.669830 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.13577577,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.10668559,\n",
      " 'Loss/RPNLoss/localization_loss': 0.002607608,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0008673378,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.24593632,\n",
      " 'learning_rate': 0.007877518}\n",
      "INFO:tensorflow:Step 20500 per-step time 0.210s\n",
      "I0109 11:19:02.712783 139661106783040 model_lib_v2.py:698] Step 20500 per-step time 0.210s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.18078795,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.1562187,\n",
      " 'Loss/RPNLoss/localization_loss': 0.057504248,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0063337837,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.40084466,\n",
      " 'learning_rate': 0.0078759305}\n",
      "I0109 11:19:02.712956 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.18078795,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.1562187,\n",
      " 'Loss/RPNLoss/localization_loss': 0.057504248,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0063337837,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.40084466,\n",
      " 'learning_rate': 0.0078759305}\n",
      "INFO:tensorflow:Step 20600 per-step time 0.210s\n",
      "I0109 11:19:23.741977 139661106783040 model_lib_v2.py:698] Step 20600 per-step time 0.210s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.13773161,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.11588499,\n",
      " 'Loss/RPNLoss/localization_loss': 0.014496281,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.001593923,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.2697068,\n",
      " 'learning_rate': 0.007874332}\n",
      "I0109 11:19:23.742179 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.13773161,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.11588499,\n",
      " 'Loss/RPNLoss/localization_loss': 0.014496281,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.001593923,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.2697068,\n",
      " 'learning_rate': 0.007874332}\n",
      "INFO:tensorflow:Step 20700 per-step time 0.210s\n",
      "I0109 11:19:44.749555 139661106783040 model_lib_v2.py:698] Step 20700 per-step time 0.210s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.45589763,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.72550917,\n",
      " 'Loss/RPNLoss/localization_loss': 0.020039221,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.020665795,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 1.2221117,\n",
      " 'learning_rate': 0.007872726}\n",
      "I0109 11:19:44.749701 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.45589763,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.72550917,\n",
      " 'Loss/RPNLoss/localization_loss': 0.020039221,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.020665795,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 1.2221117,\n",
      " 'learning_rate': 0.007872726}\n",
      "INFO:tensorflow:Step 20800 per-step time 0.210s\n",
      "I0109 11:20:05.759083 139661106783040 model_lib_v2.py:698] Step 20800 per-step time 0.210s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.036780067,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.08994391,\n",
      " 'Loss/RPNLoss/localization_loss': 0.16031183,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.005117501,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.2921533,\n",
      " 'learning_rate': 0.007871107}\n",
      "I0109 11:20:05.759226 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.036780067,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.08994391,\n",
      " 'Loss/RPNLoss/localization_loss': 0.16031183,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.005117501,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.2921533,\n",
      " 'learning_rate': 0.007871107}\n",
      "INFO:tensorflow:Step 20900 per-step time 0.210s\n",
      "I0109 11:20:26.790485 139661106783040 model_lib_v2.py:698] Step 20900 per-step time 0.210s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.08934892,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.18333885,\n",
      " 'Loss/RPNLoss/localization_loss': 0.040657606,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0072394833,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.32058486,\n",
      " 'learning_rate': 0.007869479}\n",
      "I0109 11:20:26.790646 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.08934892,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.18333885,\n",
      " 'Loss/RPNLoss/localization_loss': 0.040657606,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.0072394833,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.32058486,\n",
      " 'learning_rate': 0.007869479}\n",
      "INFO:tensorflow:Step 21000 per-step time 0.210s\n",
      "I0109 11:20:47.824192 139661106783040 model_lib_v2.py:698] Step 21000 per-step time 0.210s\n",
      "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.07191187,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.0620397,\n",
      " 'Loss/RPNLoss/localization_loss': 0.12121748,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.010836185,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.26600525,\n",
      " 'learning_rate': 0.007867842}\n",
      "I0109 11:20:47.824347 139661106783040 model_lib_v2.py:701] {'Loss/BoxClassifierLoss/classification_loss': 0.07191187,\n",
      " 'Loss/BoxClassifierLoss/localization_loss': 0.0620397,\n",
      " 'Loss/RPNLoss/localization_loss': 0.12121748,\n",
      " 'Loss/RPNLoss/objectness_loss': 0.010836185,\n",
      " 'Loss/regularization_loss': 0.0,\n",
      " 'Loss/total_loss': 0.26600525,\n",
      " 'learning_rate': 0.007867842}\n"
     ]
    }
   ],
   "source": [
    "!python model_main_tf2.py --model_dir=training/TF2/training/{PATH_TO_MODEL} --pipeline_config_path=training/TF2/training/{PATH_TO_MODEL}/pipeline.config --num_train_steps=21000 --alsologtostderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins>Exporting a Trained Inference Graph</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once our training of the model is complete, we are extracting the newly inferenced graph, which will be later use to perform the object detection. \n",
    "\n",
    "#### The following file <mark>exporter_main_v2.py</mark> uses model configuration and a trained checkpoint to get ready an object detection tensorflow graph for inference. In the output of this file, we are getting checkpoint files, a SavedModel, and a copy of the model config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-09 11:20:50.934735: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-09 11:20:52.391537: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-01-09 11:20:52.412590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 11:20:52.413022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-01-09 11:20:52.413037: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-09 11:20:52.416288: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-01-09 11:20:52.416318: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-01-09 11:20:52.417024: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-09 11:20:52.417742: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-09 11:20:52.418422: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-01-09 11:20:52.419179: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-01-09 11:20:52.419394: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-01-09 11:20:52.419446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 11:20:52.419891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 11:20:52.420300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-01-09 11:20:52.420455: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-09 11:20:52.420966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 11:20:52.421385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-01-09 11:20:52.421428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 11:20:52.421861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 11:20:52.422265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-01-09 11:20:52.422286: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-09 11:20:52.716751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-01-09 11:20:52.716773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2023-01-09 11:20:52.716779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2023-01-09 11:20:52.716898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 11:20:52.717387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 11:20:52.717825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 11:20:52.718243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21666 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W0109 11:20:53.000260 139621557650240 deprecation.py:596] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0109 11:20:59.456916 139621557650240 convolutional_keras_box_predictor.py:153] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "W0109 11:21:02.464636 139621557650240 deprecation.py:528] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "W0109 11:21:02.711286 139621557650240 deprecation.py:330] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "WARNING:tensorflow:From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
      "W0109 11:21:04.683037 139621557650240 deprecation.py:330] From /home/msc1/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
      "2023-01-09 11:21:05.030005: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-01-09 11:21:05.049455: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3699850000 Hz\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.faster_rcnn_meta_arch.FasterRCNNMetaArch object at 0x7efb10b62430>, because it is not built.\n",
      "W0109 11:21:08.292031 139621557650240 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.meta_architectures.faster_rcnn_meta_arch.FasterRCNNMetaArch object at 0x7efb10b62430>, because it is not built.\n",
      "2023-01-09 11:21:22.656549: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "W0109 11:21:44.328151 139621557650240 save.py:238] Found untraced functions such as FirstStageBoxPredictor_layer_call_fn, FirstStageBoxPredictor_layer_call_and_return_conditional_losses, mask_rcnn_keras_box_predictor_layer_call_fn, mask_rcnn_keras_box_predictor_layer_call_and_return_conditional_losses, FirstStageBoxPredictor_layer_call_fn while saving (showing 5 of 70). These functions will not be directly callable after loading.\n",
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "W0109 11:21:50.916120 139621557650240 save.py:1239] FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "INFO:tensorflow:Assets written to: ./training/TF2/training/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8/saved_model/saved_model/assets\n",
      "I0109 11:21:51.836218 139621557650240 builder_impl.py:774] Assets written to: ./training/TF2/training/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8/saved_model/saved_model/assets\n",
      "INFO:tensorflow:Writing pipeline config file to ./training/TF2/training/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8/saved_model/pipeline.config\n",
      "I0109 11:21:52.997066 139621557650240 config_util.py:253] Writing pipeline config file to ./training/TF2/training/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8/saved_model/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path ./training/TF2/training/{PATH_TO_MODEL}/pipeline.config --trained_checkpoint_dir ./training/TF2/training/{PATH_TO_MODEL}/ --output_directory ./training/TF2/training/{PATH_TO_MODEL}/saved_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "tensorflow-object-detection-training-colab.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
